# 基于 LLM 视觉模型的爱泼斯坦档案人物关系分析可行性研究

## 📋 研究简介

本研究以爱泼斯坦档案为研究对象，系统探究了基于OCR技术、大语言模型（LLM）、LLM视觉模型的人物关系分析可行性。研究通过调用DeepSeek OCR 2完成档案扫描件的文本化处理，利用DeepSeek V3.2大语言模型进行文本层面的人物关系抽取，借助DeepSeek OCR 2的LLM视觉相关功能实现档案图片的内容描述、要素识别与提取，并结合文本与图片信息进行关联分析。

### 研究目标
- 验证OCR技术（DeepSeek OCR 2）在爱泼斯坦档案文本化处理中的可行性
- 验证大语言模型（DeepSeek V3.2）在档案文本分析、人物关系抽取中的可行性  
- 验证LLM视觉模型（DeepSeek OCR 2）在档案图片分析中的可行性
- 形成一套基于LLM视觉模型的爱泼斯坦档案人物关系分析方案

### 核心创新点
- ⭐ **多模态融合分析**：结合OCR、LLM文本分析和LLM视觉分析的完整技术方案
- ⭐ **高精度文本识别**：利用DeepSeek OCR 2处理复杂档案文档，识别准确率达97.1%
- ⭐ **智能关系抽取**：基于DeepSeek V3.2实现显性和隐性人物关系的精准抽取
- ⭐ **跨模态信息关联**：实现文本与图片信息的深度融合分析

## 🎯 技术方案

### 整体架构

档案扫描件 → OCR文本化处理 → 文本关系抽取 → 图片内容分析 → 多模态关联分析 → 人物关系网络构建


### 关键技术组件

#### 1. OCR文本识别层
- **DeepSeek OCR 2 FreeOCR功能**：处理清晰文本、模糊文本、手写批注等复杂场景
- **多语言支持**：适配中英文混合文本识别
- **高效率处理**：支持批量处理

#### 2. 文本分析层  
- **命名实体识别**：识别文本中的人物、地点、事件等实体
- **关系抽取**：基于规则和深度学习方法抽取人物关联关系
- **语义分析**：挖掘显性和隐性的人物关系

#### 3. 图片分析层
- **内容描述**：利用LLM视觉模型生成图片文本描述
- **要素识别**：识别人物身份、动作、场景、物品等核心要素
- **特征提取**：提取图片中的关键视觉信息

#### 4. 关联融合层
- **多模态信息整合**：结合文本和图片信息进行关联分析
- **关系补充完善**：通过图片信息补充文本层面未捕捉的关系细节
- **综合结果输出**：形成完整的多维度人物关系分析结果

## 📁 项目结构

```
├── main.tex              # 论文主文档（LaTeX格式）
├── reference.bib         # 参考文献数据库（BibTeX格式）
├── figures/              # 实验图表与示例图片
│   ├── ocryingyong.pdf          # OCR应用场景图
│   ├── deepseekocr.pdf          # DeepSeek OCR模型架构图
│   ├── dsocr2.pdf               # DeepSeek OCR 2模型架构对比图
│   ├── 框架.png                 # 研究框架图
│   ├── test1.png                # OCR处理示例图
│   ├── test1result.png          # OCR处理结果图
│   ├── test2.jpg                # 图片分析示例图
│   └── test2result.png          # 图片要素识别结果图
└── README.md             # 项目说明文档
```

## 🚀 研究方法与实验设计

### 研究流程
1. **数据准备**：收集爱泼斯坦档案官方扫描件（约350万页文本，18万张图片）
2. **文本化处理**：调用DeepSeek OCR 2进行扫描件文本化转换
3. **文本分析**：利用DeepSeek V3.2进行命名实体识别和关系抽取
4. **图片分析**：借助DeepSeek OCR 2视觉功能进行图片描述和要素提取
5. **关联分析**：融合文本与图片信息，完善人物关系挖掘结果

### 实验设置
- **硬件环境**：RTX 4060 Laptop GPU
- **数据规模**：350万页文本扫描件，18万张图片
- **处理参数**：支持384px到1344px不同分辨率图像
- **评估方法**：人工抽检验证，对比传统方法效果

### 性能指标
- **OCR识别准确率**：整体97.1%，模糊文本处理优势显著
- **关系抽取精准度**：显性关系96.7%，隐性关系85.1%
- **图片描述准确率**：有效图片描述准确率达91.5%
- **处理效率**：384px分辨率6秒/页，1344px分辨率40秒/页

## 🔧 技术特点与优势

### DeepSeek OCR 2优势
- **高准确率**：97%识别准确率，远超传统OCR模型
- **低资源消耗**：仅需100 tokens/页，效率提升60%以上
- **强适应性**：支持模糊文本、手写批注、复杂布局处理
- **多模态集成**：集文本识别、图片描述、要素提取于一体

### DeepSeek V3.2优势
- **上下文理解**：能挖掘文本中隐藏的隐性关系
- **高覆盖度**：相比传统规则法覆盖度显著提升
- **多语言支持**：适配中英文混合文本处理
- **灵活部署**：可直接调用API完成分析，无需复杂训练

## 📊 研究成果

### 核心发现
1. **技术可行性验证**：OCR+LLM+LLM视觉模型组合可实现档案人物关系的多维度分析
2. **性能优势确认**：DeepSeek系列模型在复杂档案处理中表现优异
3. **方法有效性证明**：多模态融合分析相比单一模态分析效果显著提升
4. **实用价值体现**：为同类机密档案智能化分析提供可落地的技术路径

### 典型应用效果
- 成功识别爱泼斯坦与特朗普、马斯克、比尔·盖茨等核心人物的复杂关联
- 准确抽取社交往来、利益关联、行程交集等多类型人物关系
- 有效补充图片中的人物交互细节和场景背景信息
- 构建了完整的多维度人物关系分析框架

## 📚 使用说明

### 编译要求
- XeLaTeX 编译器
- 完整的TeX发行版（推荐TeX Live）
- 支持中文的系统字体环境

### 编译步骤
```bash
# 完整编译流程
xelatex main.tex
bibtex main.aux  
xelatex main.tex
xelatex main.tex

# 或使用自动化编译
latexmk -xelatex main.tex
```

## 📄 免责声明

本研究基于美国司法部公开的爱泼斯坦档案数据进行技术验证，所有分析结果仅供学术研究参考，不构成对任何个人或事件的定性判断。研究严格遵守数据最小化原则和学术诚信规范。本项目在编写过程中使用了AIGC作为工具。

## 引用

本项目非学术论文，不建议引用。如需引用，请按照[LICENSE](./LICENSE)相关规定使用。